{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CS6140 Machine Learning: Assignment 3 (F22) (Total Points: 100)\n",
        "## Prof. Ahmad Uzair\n"
      ],
      "metadata": {
        "id": "0c2LDnsAzazG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ROC and Precision Recall curves\n",
        "\n",
        "1. Generate data: Simulate a binary classification problem by generating a vector of class labels. Size 100. Generate a vector of predictor estimates using a random number generator. **(5 Points)**\n",
        "\n",
        "2. Calculate and plot ROC and Precision-Recall curves. **(20 Points)**\n",
        "\n",
        "3. Match your curve generated with sklearn. **(5 Points)**\n",
        "\n"
      ],
      "metadata": {
        "id": "4lxv7JNcAqrh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest classifier \n",
        "1. Load iris data set.\n",
        "\n",
        "```{python}\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, plot_confusion_matrix\n",
        "```\n",
        "\n",
        "Investigate following parameters of Random Forest classifier and tune them using Randomized Search and Grid Search. \n",
        "\n",
        "```{python}\n",
        "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt','log2']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 1000,10)]\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 8, 11,14]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4,6,8]\n",
        "```\n",
        "2. Use seed 1 to split data in 80-20 train-test configuration.  Train a Random Forest classifier with each unique configuration and record train/test accuracy, precision and recall in the results dataframe. This dataframe will have 5 columns (each corresponding to tuning parameter) and each row will correspond to each unique configuration. 5x5x5x5x5 rows. Analyse of the impact of each tuning parameter on predictor performance. **(15 Points)**\n",
        "\n",
        "3. From the results of the above find the best estimators and use them for classifcation once again and evaluate the performance using 10 fold cross validation. **(15 Points)**\n",
        "\n"
      ],
      "metadata": {
        "id": "98odE0ka5bPc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Heirarchical Agglomerative Clustering HAC\n",
        "\n",
        "Load iris dataset from sklearn.\n",
        "```{python}\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "```\n",
        "1. Implement HAC algorithm. Use the abstract class definition provided below. **(15 Points)**\n",
        "\n",
        "2. Test your code first with uni-variate data as following; **(10 Points)**\n",
        "```{python}\n",
        "x = {'JAN':31.9, 'FEB':32.3, 'MAR':35, 'APR':52, 'MAY':60.8, 'JUN':68.7, 'JUL':73.3, 'AUG':72.1, 'SEP':65.2, 'OCT':54.8, 'NOV':40, 'DEC':38}\n",
        "hac = HAC(param={'dist': 'eucl'})\n",
        "hac.fit(x)\n",
        "for c in hac.dendrogram:\n",
        "    print(c)\n",
        "```\n",
        "Expected output:\n",
        "```\n",
        "(0, ['JAN', 'FEB'], 0.4)\n",
        "(1, ['JUL', 'AUG'], 1.2)\n",
        "(2, ['NOV', 'DEC'], 2.0)\n",
        "(3, ['APR', 'OCT'], 2.8)\n",
        "(4, ['JAN', 'FEB', 'MAR'], 2.9)\n",
        "(5, ['JUN', 'SEP'], 3.5)\n",
        "(6, ['APR', 'OCT', 'MAY'], 7.4)\n",
        "```\n",
        "\n",
        "2. Fit the HAC model to iris dataset. Print the heirarchy of clusters creatively. It need not to be a dendrogram but you can use [sklearn implementation](https://scikit-learn.org/stable/auto_examples/cluster/plot_agglomerative_dendrogram.html#sphx-glr-auto-examples-cluster-plot-agglomerative-dendrogram-py) for comparison. **(15 Points)**\n",
        "\n"
      ],
      "metadata": {
        "id": "vQzO2sQmzfDg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pO831QzizP5x",
        "outputId": "852ae183-3f34-4aa4-faef-2ece39119997"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.HAC at 0x7f6b46433050>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "class HAC:\n",
        "  def __init__(self, X, param):\n",
        "    self.X = x\n",
        "    self.__distances__(param['dist'])\n",
        "    \n",
        "  \n",
        "  def __distances__(self, dist='eucl'):\n",
        "    '''\n",
        "    Implement __distances__ method to caculate pair-wise distances \n",
        "    among datapoint in X with respect to distance measures\n",
        "    - eucl : eucledean distance\n",
        "    - manh : manhattan\n",
        "    - misk : miskownski\n",
        "    '''\n",
        "    if dist not in ['eucl', 'manh', 'misk']:\n",
        "      raise Exception('Not a valid dist measure. Choose among eucl, manh, misk')\n",
        "    \n",
        "    self.C = None\n",
        "    \n",
        "  def __merge__(self):\n",
        "    '''\n",
        "    Implement __merge__ method to recursively merge the nearest datapoints in X\n",
        "    using pair-wise distances matrix X. \n",
        "    Save the merge results at each iteration/'recursive call' \n",
        "    in dendrogram list of clusters.\n",
        "    '''\n",
        "    self.denrogram = None\n",
        "\n",
        "  def __display__(self):\n",
        "    '''\n",
        "    Implement __display__ method to cretively show the contents of dendrogram.    \n",
        "    '''\n",
        "    pass\n",
        "\n",
        "  def fit(self, X):\n",
        "    self.X = list(x.values())\n",
        "    self.labels = list(x.keys())\n",
        "    self.__distances__()\n",
        "    self.dendrogram = list()\n",
        "    self.__merge__()"
      ]
    }
  ]
}